# NLP_and_Multimodal_Distillation

### NLP

#### Pre-training

() Contrastive Distillation on Intermediate Representations for Language Model Compression. [link](https://arxiv.org/abs/2009.14167.pdf)

#### Text Retrieval

() [link]()
() [link]()
() [link]()
() [link]()



() Adversarial Retriever-Ranker for dense text retrieval. [link](https://arxiv.org/abs/2110.03611.pdf)

() LED: Lexicon-Enlightened Dense Retriever for Large-Scale Retrieval. [link](https://arxiv.org/pdf/2208.13661.pdf)

() In defense of dual-encoders for neural ranking. [link](https://proceedings.mlr.press/v162/menon22a/menon22a.pdf)

(X) EMBEDDISTILL: A Geometric Knowledge Distillation For Information Retrieval. [link](https://openreview.net/pdf?id=-aEuKX6zQKmr)


### Multimodal Learning

() ADVL: Adaptive Distillation For Vision-Language Task. [link](https://openreview.net/pdf?id=8-2sjUPp_YD)

() The Modality Focusing Hypothesis: Towards Understanding Crossmodal Knowledge Distillation. [link](https://openreview.net/pdf?id=w0QXrZ3N-s)

